% $Header$

\documentclass[aspectratio=1610]{beamer}

\mode<presentation>
{%
  \usetheme{Boadilla}
}


\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{%
    animate,
    graphicx,
    varwidth,
    tcolorbox,
    clrscode3e,
    tikz,
    mathtools,
}
\usetikzlibrary{shapes.multipart}

\tikzset{%
    block/.style={%
        font=\sffamily,
        draw=black,
        thin,
        fill=pink!50,
        rectangle split,
        rectangle split horizontal,
        rectangle split parts=#1,
        outer sep=0pt
    },
    gblock/.style={%
        block,
        rectangle split parts=#1,
        fill=green!30
    },
    invisible/.style={opacity=0},
    visible on/.style={alt={#1{}{invisible}}},
    alt/.code args={<#1>#2#3}{%
      \alt<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}} % \pgfkeysalso doesn't change the path
    },
}

\graphicspath{{../../imgs/}}

% alert a whole line (especially for algorithms)
\newcommand{\alertline}{%
 \usebeamercolor[fg]{normal text}%
 \only{\usebeamercolor[fg]{alerted text}}}

% floor command
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}

\title[ALG25 - Lecture 3]
{Divide and Conquer \& The Master Theorem}

\subtitle
{Algorithms and Datastructures, F25, Lecture 3}

\author[Andreas H. Høeg-Petersen]
{Andreas Holck Høeg-Petersen}

\institute[AAU]{%
  Department of Computer Science\\
  Aalborg University
}

\date {\today}

\pgfdeclareimage[height=0.5cm]{university-logo}{../../imgs/aau-logo}
\logo{%
    \begin{tikzpicture}[overlay,remember picture]
        \node[left=0.2cm] at (current page.30){\pgfuseimage{university-logo}};
    \end{tikzpicture}
}

\AtBeginSection[]
{%
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Opdateringer}{}
    \begin{itemize}
        \item Første programmeringsopgave er lagt op - har alle set den?
        \item Fra evaluering:
            \begin{itemize}
                \item Fordeling af tid til første og andet session af exercises
                    var lidt skæv
                \item Klasserumsinteraktion og trin-for-trin gennemgang af
                    algoritmen var godt!
            \end{itemize}
    \end{itemize}
\end{frame}


\begin{frame}{Outline}
  \tableofcontents
\end{frame}


\section{Divide and Conquer}

\begin{frame}{Divide and Conquer}{Algoritmiske teknikker}
    Divide-and-conquer er en effektiv teknik til at designe effektive
    algoritmer til at løse komplekse problemer ved at bryde dem ned i mindre
    dele. Ofte giver det en asymptotisk køretid i $\Theta(n \log n)$.

    \pause \medskip
    Metoden har overordnet set 3 skridt:

    \pause
    \begin{description}[<+->][Combine]
        \item[Divide] Del problemet op i et eller flere sub-problemer, der er
            mindre instanser af det samme problem
        \item[Conquer] Løs sub-problemerne rekursivt
        \item[Combine] Kombiner løsningerne på sub-problemerne til en løsning på
            det oprindelige problem
    \end{description}

    \pause
    Hvis problemet er småt nok (\alert{base case}), løses det uden videre.
    Ellers (\alert{recursive case}) fortsætter man rekursionen.
\end{frame}

\begin{frame}{Divide and Conquer}{Rekursion???}
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{recursion}
        \caption{Google søgning på `recursion'}
        \label{fig:recursion}
    \end{figure}

    \pause
    \begin{example}[Fibonacci-sekvensen]
        Det næste tal i Fibonacci-sekvensen er givet ved at summere de to
        foregående elementer. Den starter med 1, 1, 2, 3, 5, 8, 13, \ldots. Men
        den kan dermed også defineres rekursivt, således at det $i$'ende
        elementer er givet ved $F(i) = F(i-1) + F(i-2)$.
    \end{example}
\end{frame}

\begin{frame}{Divide and Conquer}{Algoritmisk rekursion}
    I algoritmisk forstand forstår vi en rekursion $T(n)$ således, at der for en
    tilpas stor konstant $n_0$ skal gælde følgende:

    \begin{enumerate}
        \item For alle $n < n_0$ har vi at $T(n) = \Theta(1)$ --- dvs. $T(n)$ er
            konstant
        \item For alle $n \geq n_0$ må alle stier af rekursionen ende i en
            defineret base case inden for et \alert{endeligt} antal rekursive
            kald.
    \end{enumerate}

    \pause
    I kurset her gælder det for alle rekursioner, vi ser på, men det er værd at
    have in mente, hvis I selv designer algoritmer, som gør brug af rekursion.
\end{frame}

\begin{frame}{Divide and Conquer}{Eksempler}
    I dag skal vi se på to eksempler på divide-and-conquer-algoritmer:

    \begin{itemize}
        \item Merge sort
        \item Quicksort
    \end{itemize}
\end{frame}

\section{Merge sort}

\begin{frame}{Merge sort}{Den kender I jo!}
    \begin{itemize}
        \item En af de mest berømte og benyttede sorteringsalgoritmer --- og en
            af de første til at blive implementeret i en computer (ca.\ 1945 af
            John von Neumann)
        \item Ide:
            \begin{description}
                \item[Divide] Opdel sekvensen i to lige store sub-sekvenser og kald
                    algoritmen rekursivt
                \item[Conquer] Når algoritmen modtager en sekvens med kun et element,
                    returner det trivielt sorterede element
                \item[Combine] Kombiner de sorterede sub-sekvenser, så
                    sorteringsrækkefølgen overholdes
            \end{description}
    \end{itemize}
\end{frame}

\begin{frame}{Merge sort}{Pseudo-kode del 1}
    \begin{columns}
        \column{.5\textwidth}

        \begin{itemize}[<+->]
            \small
            \item Input: en sekvens $A[1:n]$ og to \alert{indicies} $p, r$ hvor
                $1 \leq p \leq r \leq n$
            \item Ved første kald er $p=1$ og $r=n$, altså
                $\proc{Merge-Sort}(A,1,n)$
            \item I linie 3 finder vi midtpunktet mellem $p$ og $r$
            \item I linie 4 og 5 kalder vi rekursivt for den ene og anden
                halvdel af sekvensen
            \item I linie 5 kombinerer (`merger') vi de to halvdele sammen
        \end{itemize}

        \column{.5\textwidth}

        \begin{minipage}{\textwidth}
            \centering
            \begin{tcolorbox}

                \vspace{-\abovedisplayskip}
                \begin{codebox}
                    \Procname{$\proc{Merge-Sort}(A,p,r)$}
                    \li \If $p \geq r$ \Then
                        \li \Return
                    \End
                    \li $q \gets \floor{(p+r)/2}$
                    \li \proc{Merge-Sort}($A,p,q)$
                    \li \proc{Merge-Sort}($A,q+1,r$)
                    \li \proc{Merge}($A,p,q,r$)
                \end{codebox}
            \end{tcolorbox}
        \end{minipage}
        
    \end{columns}
\end{frame}

\begin{frame}{Merge sort}{Merge-operationen}
    Merge-operationen er et rædselsfuldt monster i CLRS\ldots!

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{merge-clrs}
        \caption{Ew!!}
        \label{fig:merge-clrs}
    \end{figure}
\end{frame}

\begin{frame}{Merge sort}{Merge-operationen}
    En lidt mere venlig version kunne se sådan her ud:

    \centering
    \begin{minipage}{.8\textwidth}
        \scriptsize
        \begin{tcolorbox}
            
            \vspace{-\abovedisplayskip}
            \begin{codebox}
                \Procname{$\proc{Merge}(A,p,q,r)$}
                \li let $B[0:r-p]$ be a new array with 0-index
                \li \For $i \gets 0$ \To $r-p$ \Do
                    \li $B[i] = A[i+p]$
                \End
                \li $i \gets 0$, $j \gets (r-q)$
                \li \For $k \gets p$ \To $r$ \Do
                    \li \If $(i + p) > q$ \Then
                        \li $A[k] \gets B[j]$
                        \li $j \gets j + 1$
                    \li \ElseIf $(j + q) > r$ \Then
                        \li $A[k] \gets B[i]$
                        \li $i \gets i + 1$
                    \li \ElseIf $B[j] < B[i]$ \Then
                        \li $A[k] \gets B[j]$
                        \li $j \gets j + 1$
                    \li \Else
                        \li $A[k] \gets B[i]$
                        \li $i \gets i + 1$
                    \End
                \End
            \end{codebox}
        \end{tcolorbox}
    \end{minipage}
\end{frame}

\begin{frame}{Merge sort}{Merge-operationen}
    Og her endda med forståelige navne:

    \centering
    \begin{minipage}{.8\textwidth}
        \scriptsize
        \begin{tcolorbox}
            
            \vspace{-\abovedisplayskip}
            \begin{codebox}
                \Procname{$\proc{Merge}(A,p,q,r)$}
                \li $\id{low} \gets p, \id{mid} \gets q+1, \id{high} \gets r+1$
                \li let $B[0:\id{high}-\id{low}]$ be a new array with 0-index
                \li \For $i \gets 0$ \To $\attrib{B}{length}$ \Do
                    \li $B[i] = A[i+\id{low}]$
                \End
                \zi
                \li $i \gets 0$, $j \gets (\id{mid}-\id{low})$
                \li \For $k \gets \id{low}$ \To $\id{high}$ \Do
                    \li \If $(i + \id{low}) \geq \id{mid}$ \Then
                        \li $A[k] \gets B[j]$
                        \li $j \gets j + 1$
                    \li \ElseIf $(j + \id{low}) \geq \id{high}$ \Then
                        \li $A[k] \gets B[i]$
                        \li $i \gets i + 1$
                    \li \ElseIf $B[j] < B[i]$ \Then
                        \li $A[k] \gets B[j]$
                        \li $j \gets j + 1$
                    \li \Else
                        \li $A[k] \gets B[i]$
                        \li $i \gets i + 1$
                    \End
                \End
            \end{codebox}
        \end{tcolorbox}
    \end{minipage}
\end{frame}

\begin{frame}{Merge sort}{Merge-operationen}
    \begin{columns}
        \column{.5\textwidth}

        \centering
        \begin{minipage}{\textwidth}
            \scriptsize
            \begin{tcolorbox}
                
                \vspace{-\abovedisplayskip}
                \begin{codebox}
                    \Procname{$\proc{Merge}(A,p,q,r)$}
                    \li \alertline<2>$\id{low} \gets p,
                                      \id{mid} \gets q+1,
                                      \id{high} \gets r+1$
                    \li \alertline<3>let $B[0:\id{high}-\id{low}]$ be
                    \Startalign{let $B$}
                    \>  \alertline<3>a new array with 0-index
                    \Stopalign

                    \li \alertline<3>\For $i \gets 0$ \To $\attrib{B}{length}$ 
                    \li     \Do
                    \alertline<3>$B[i] = A[i+\id{low}]$
                            \End
                    \zi

                    \li \alertline<4>$i \gets 0$, $j \gets (\id{mid}-\id{low})$
                    \li \alertline<5>\For $k \gets \id{low}$ \To $\id{high}$ 
                    \li     \Do
                                \alertline<6>\If $(i + \id{low}) \geq \id{mid}$
                    \li             \Then
                                        \alertline<6>$A[k] \gets B[j]$
                    \li                 \alertline<6>$j \gets j + 1$
                    \li         \ElseIf \alertline<7>$(j + \id{low}) \geq \id{high}$
                    \li             \Then
                                        \alertline<7>$A[k] \gets B[i]$
                    \li                 \alertline<7>$i \gets i + 1$
                    \li         \ElseIf \alertline<8>$B[j] < B[i]$
                    \li             \Then
                                        \alertline<8>$A[k] \gets B[j]$
                    \li                 \alertline<8>$j \gets j + 1$
                    \li         \ElseNoIf
                    \li                 \alertline<9>$A[k] \gets B[i]$
                    \li                 \alertline<9>$i \gets i + 1$
                                \End
                            \End
                \end{codebox}
            \end{tcolorbox}
        \end{minipage}

        \column{.53\textwidth}
        \pause

        \begin{itemize}[<+->]
            \scriptsize
            \item Vi lader $low = p, mid = q+1$ og $high = r+1$
            \item Kopier $A[p:r]$ til $B[0:r-p]$
            \item $i$ og $j$ peger på første og anden del af $B$
            \item $k$ løber igennem alle indicies i $A[p:r]$
            \item Hvis $i$ er forbi midten, tag næste element fra $B[j:r-p]$ og
                inkrementer $j$
            \item Hvis $j$ er forbi slutningen, tag næste element fra $B[0:q-p]$
                og inkrementer $i$
            \item Hvis $B[j]$ er lavere end $B[i]$, sæt $A[k]$ til $B[j]$ og
                inkrementer $j$
            \item Ellers, sæt $A[k]$ til $B[i]$ og inkrementer $i$
            \item Vi har nu lagt elementerne fra $B$ tilbage i $A$ i sorteret
                rækkefølge!
            \item Forskellen fra CLRS er, at vi samler $L$ og $R$ i et enkelt
                array $B$
            \item \ldots og at vi klarer resten i et enkelt loop (fremfor 3,
                eew!)
        \end{itemize}
    \end{columns}

\end{frame}


\begin{frame}{Merge sort}{Example}

    % courtesy of https://tex.stackexchange.com/questions/592155/how-to-draw-a-merge-sort-algorithm-figure

    \def\lvld{1.1}                  % Choose level distance
    \pgfmathsetmacro\shft{-6*\lvld} % Calculate the yshift for the green tree

    \centering
    \begin{tikzpicture}[
        level distance=\lvld cm,
        level 1/.style={sibling distance=4cm},
        level 2/.style={sibling distance=2cm},
        level 3/.style={sibling distance=1cm},
        edgedown/.style={edge from parent/.style={draw=red,thick,-latex}},
        edgeup/.style={edge from parent/.style={draw=green!50!black,thick,latex-}}
    ]
  
        % GREEN TREE (drawn first to let the middle line filled in pink)

        \node[gblock=7,yshift=\shft cm,visible on= <16->] (A') {%
            3 \nodepart{two} 9 \nodepart{three} 10 \nodepart{four} 27
                \nodepart{five} 39 \nodepart{six} 43 \nodepart{seven} 82
            }
            [grow=up,edgeup]
            child[visible on= <12->] {node[gblock=3,visible on= <15->] (B2') {9 \nodepart{two} 10 \nodepart{three} 82}
                child[visible on= <14->] {node[gblock=1,visible on= <14->] (C4') {10}
                    child[visible on= <14->] {node[gblock=1] (D7') {10}}
                }
                child[visible on= <12->] {node[gblock=2,visible on= <12->] (C2') {9 \nodepart{two} 82}
                    child[visible on= <12->] {node[gblock=1] (D3') {82}}
                    child[visible on= <12->] {node[gblock=1] (D4') {9}}
                }
            }
            child[visible on= <5->] {node[gblock=4, visible on= <9->] (B1') {3 \nodepart{two} 27 \nodepart{three} 39 \nodepart{four} 43}
                child[visible on=<8->] {node[gblock=2, visible on= <8->] (C3') {3 \nodepart{two} 43}
                    child[visible on=<8->] {node[gblock=1] (D5') {3}}
                    child[visible on=<8->] {node[gblock=1] (D6') {43}}
                }
                child[visible on=<5->] {node[gblock=2] (C1') {27 \nodepart{two} 39}
                    child[visible on=<5->] {node[gblock=1] (D1') {27}}
                    child[visible on=<5->] {node[gblock=1] (D2') {39}}
                }
            };
            
            
        % PINK TREE
        
        \node[block=7, visible on=<1->] (A) {39 \nodepart{two} 27 \nodepart{three} 43 \nodepart{four} 3 \nodepart{five} 9 \nodepart{six}82 \nodepart{seven}10}
            [grow=down,edgedown]
            child[visible on=<2->] {node[block=4] (B1) {39 \nodepart{two} 27 \nodepart{three} 43 \nodepart{four} 3}
                child[visible on=<3->] {node[block=2] (C1) {39 \nodepart{two} 27}
                    child[visible on=<4->] {node[block=1] (D1) {39}}
                    child[visible on=<4->] {node[block=1] (D2) {27}}
                }
                child[visible on=<3->] {node[block=2] (C2) {43 \nodepart{two} 3}
                    child[visible on=<7->] {node[block=1] (D3) {43}}
                    child[visible on=<7->] {node[block=1] (D4) {3}}
                }
            }
            child[visible on=<2->] {node[block=3] (B2) {9 \nodepart{two} 82 \nodepart{three} 10}
                child[visible on=<10->] {node[block=2] (C3) {9 \nodepart{two} 82}
                    child[visible on=<11->] {node[block=1] (D5) {9}}
                    child[visible on=<11->] {node[block=1] (D6) {82}}
                }
                child[visible on=<10->] {node[block=1] (C4) {10}
                    child[visible on=<13->] {node[block=1] (D7) {10}}
                }
            };
    \end{tikzpicture}

\end{frame}


\begin{frame}{Merge sort}{Intuitiv analyse}
    I næste del af forelæsningen lærer vi om et mere generelt trick til at
    analysere køretid for rekursive algoritmer, men til en start ser vi på en
    intuitiv måde at gå til analysen på.
    \begin{columns}

        \column{.6\textwidth}
        \small

        \pause
        \begin{itemize}[<+->]
            \small
            \item Vi noterer os, at \proc{Merge} operationen er $\Theta(n)$
            \item De to rekursitve kald halverer begge input-størrelsen, altså
                har vi to kald med $n/2$
            \item I base case, hvor $n\leq1$ og inputtet er trivielt sorteret,
                er køretiden $\Theta(1)$ (konstant)
            \item Vi har altså: 
                \[ T(n) = \begin{cases*}
                    \Theta(1) & if $n \leq 1$ \\
                    2T(n/2) + \Theta(n) & otherwise
                \end{cases*}
                \]
            \item Spørgsmålet er så, hvor mange gange kan vi halvere $n$ før,
                at vi når til base case?
            \item Dette er faktisk selve definitionen på base-2 logaritmen,
                $\log_2$!
        \end{itemize}
    
        \column{.4\textwidth}
        \centerline{\includegraphics<7>[width=.9\textwidth]{recursion-tree}}

    \end{columns}
\end{frame}

\begin{frame}{Merge sort}{Intuitiv analyse}
    På hvert `niveau' i træet --- som der er $\log_2 n$ af --- skal vi samlet set
    foretage $\Theta(n)$ operationer. F.eks., når vi er på niveau 2, har vi
    halveret $n$ to gange, så vi har $4$ lister af størrelse $n/(2*2) =
    n/4$, og tydeligvis er $4(n/4) = n$.

    \centerline{%
        \includegraphics[width=0.8\textwidth]{mergesort-analysis-by-recursion-tree}
    }
    
    \pause
    Dermed kan vi sige, at køretiden for \proc{Merge-Sort} er $T(n) = \Theta(n
    \log_2 n)$!
\end{frame}

\begin{frame}{Vi renser lige hovedet\ldots}{\ldots inden vi går til næste
    algoritme!}
    \centering
    \animategraphics[loop,autoplay,width=.8\textwidth]{10}{deep-breaths-gif/deep-breaths-}{0}{39}
\end{frame}


\section{Quicksort}

\begin{frame}{Quicksort}{Endnu en klassiker}
    Quicksort er en anden meget populær sorteringsalgoritme, der ligeledes
    følger divide-and-conquer-metoden. I worst-case er dens køretid
    $\Theta(n^2)$, men i praksis er den typisk hurtigere end de fleste andre
    alternativer --- og med en simpel modifikation, kan man (næsten) sikre sig,
    at køretiden er $\Theta(n \log n)$. Derudover er dens pladsforbrug mindre
    end for merge sort, og implementationen er noget simplere.
\end{frame}


\begin{frame}{Quicksort}{Divide-and-conquer}
    De tre dele af divide-and-conquer-metoden for quicksort er:

    \begin{description}[Combine]
        \pause
        \item[Divide] Vælg et \alert{pivot element} $p$, og del input sekvensen
            op i en `lav' del og en `høj' del således, alt i den lave del er
            mindre end $p$ og alt i den høje er større end eller lig med $p$.
            Indsæt $p$, så den skiller de to.
        \pause
        \item[Conquer] Kald quicksort rekursivt på de to halvdele.
        \pause
        \item[Combine] Her behøver vi ikke gøre noget, for når vi når til bunds
            i rekursionen, så er begge sub-arrays sorterede.
    \end{description}
\end{frame}


\begin{frame}{Quicksort}{Pseudo-kode del 1}
    \begin{columns}
        \column{.5\textwidth}

        \begin{itemize}[<+->]
            \small
            \item Input: en sekvens $A[1:n]$ og to \alert{indicies} $p, r$ hvor
                $1 \leq p \leq r \leq n$
            \item Ved første kald er $p=1$ og $r=n$, altså
                $\proc{QuickSort}(A,1,n)$
            \item I linie 2 kalder vi proceduren \proc{Partition}, som deler $A$
                i to og returnerer indexet på pivot-elementet
            \item I linie 3 og 4 kalder vi rekursivt for den ene og anden
                del af sekvensen
            \item Og så behøver vi ikke gøre mere!
        \end{itemize}

        \column{.5\textwidth}

        \begin{minipage}{\textwidth}
            \centering
            \begin{tcolorbox}

                \vspace{-\abovedisplayskip}
                \begin{codebox}
                    \Procname{$\proc{QuickSort}(A,p,r)$}
                    \li \If $p < r$ \Then
                    \li     $q \gets \proc{Partition}(A,p,r)$
                    \li     \proc{QuickSort}($A,p,q-1)$
                    \li     \proc{QuickSort}($A,q+1,r$)
                        \End
                \end{codebox}
            \end{tcolorbox}
        \end{minipage}
        
    \end{columns}
\end{frame}

\begin{frame}{Quicksort}{Pseudo-kode del 2}
    \begin{columns}
        \column{.5\textwidth}

        \begin{itemize}[<+->]
            \small
            \item Vælg \alert{pivot-elementet} $x$ til at være det sidste i
                sekvensen, $A[r]$
            \item $i$ er det sidste index i den lave del, $j$ er det første
                index i den høje del
            \item Vi løber igennem alle elementer, bortset fra pivot-elementet
            \item I linie 4 tjekker vi, om $A[j]$ hører til i den lave del (er
                mindre end $x$)
            \item I linie 5 `gør vi plads' i den lave ende ved at inkrementere
                $i$ (bemærk at på dette tidspunkt er $A[i] > x$)
            \item I linie 6 bytter vi $A[j]$ (som er mindre end $x$) ud med
                $A[i]$ (som er højere end $x$)
            \item Efter loopet flytter vi $x$ til den første plads i den høje
                del, $A[i + 1]$ --- dermed er alt i $A[p:i] \leq x$ og alt i
                $A[i+2:r] \geq x$
        \end{itemize}

        \column{.5\textwidth}

        \begin{minipage}{\textwidth}
            \centering
            \begin{tcolorbox}

                \vspace{-\abovedisplayskip}
                \begin{codebox}
                    \Procname{$\proc{Partition}(A,p,r)$}
                    \li $x \gets A[r]$
                    \li $i \gets p-1$
                    \li \For $j \gets p$ \To $r-1$
                        \Do
                    \li     \If $A[j] \leq x$ \Then
                    \li         $i \gets i + 1$
                    \li         exchange $A[i]$ with $A[j]$
                            \End
                        \End
                    \li exhange $A[i+1]$ with $x$
                    \li \Return $i+1$
                \end{codebox}
            \end{tcolorbox}
        \end{minipage}
        
    \end{columns}
\end{frame}

\begin{frame}{Quicksort}{Pseudo-kode del 2}
    \begin{columns}
        \column{.5\textwidth}

        \begin{overlayarea}{\linewidth}{5cm}
            \begin{itemize}
                \small
                \item Vælg \alert{pivot-elementet} $x$ til at være det sidste i
                    sekvensen, $A[r] = 4$
                \item Vi har
                    $i=\only<1>{0}\only<2-4>{1}\only<5>{2}\only<6->{3}$ og %
                    $j=\only<1>{1}\only<2>{2}\only<3>{3}\only<4>{4}%
                    \only<5>{5}\only<6>{6}\only<7>{7}\only<8->{8}$
                \only<1>{%
                \item Vi sammenligner $A[j]=2$ med \alert{pivot-elementet} og
                    ser, at det er mindre, så vi inkrementerer $i$ og bytter
                    $A[i]$ med $A[j]$ (men da $i=j=1$ sker der ingenting lige
                    nu). Når loopet fortsætter, inkrementeres $j$
                }
                \only<2>{%
                \item Vi sammenligner $A[j]=8$ med $4$ og ser, at det er større,
                    så vi gør intet andet end at inkrementere $j$
                }
                \only<3>{%
                \item Igen, vi ser $A[j]=7$ er større end $4$ og inkrementerer
                    blot $j$
                }
                \only<4>{%
                \item Nu ser vi $A[j]=1$ som er mindre end vores pivot-element,
                    så vi inkrementerer $i$ og bytter plads på $A[i]$ og $A[j]$
                    inden $j$ inkrementeres
                }
                \only<5>{%
                \item $A[j]=3$ er mindre end 4, så vi øger $i$ med 1 og bytter
                    7 og 3 (altså $A[3]$ og $A[5]$)
                }
                \only<6>{%
                \item For $j=6$ er $A[j]=5$, hvilket er større end 4, så loopet
                    kan fortsætte
                }
                \only<7>{%
                \item \ldots og igen, 6 er større end 4, så vi gør ikke noget
                }
                \only<8>{%
                \item Til sidst bytter vi $A[i+1]=8$ med vores pivot-element, og
                    dermed er alt i $A[p:i]$ mindre end (eller lig med) 4, mens
                    alt i $A[i+2:r]$ er større end 4
                }
                \only<9->{%
                \item Bum! Nu kan vi returnere indexet på pivot-elementet og
                    gentage proceduren rekursivt for de to sub-arrays
                }
            \end{itemize}
        \end{overlayarea}

        \vfill
        \begin{overprint}
            \onslide<1>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-a}}
            \onslide<2>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-b}}
            \onslide<3>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-c}}
            \onslide<4>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-d}}
            \onslide<5>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-e}}
            \onslide<6>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-f}}
            \onslide<7>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-g}}
            \onslide<8>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-h}}
            \onslide<9>\centerline{\includegraphics[width=0.8\textwidth]{quicksort/example-i}}
        \end{overprint}

        \column{.5\textwidth}

        \begin{minipage}{\textwidth}
            \centering
            \begin{tcolorbox}

                \vspace{-\abovedisplayskip}
                \begin{codebox}
                    \Procname{$\proc{Partition}(A,p,r)$}
                    \li $x \gets A[r]$
                    \li $i \gets p-1$
                    \li \For $j \gets p$ \To $r-1$
                        \Do
                    \li     \If $A[j] \leq x$ \Then
                    \li         $i \gets i + 1$
                    \li         exchange $A[i]$ with $A[j]$
                            \End
                        \End
                    \li exhange $A[i+1]$ with $x$
                    \li \Return $i+1$
                \end{codebox}
            \end{tcolorbox}
        \end{minipage}
        
    \end{columns}
\end{frame}

\begin{frame}{Quicksort}{Kompleksitet}
    \proc{Quicksort} er \alert{meget afhængig} af, hvordan inputtet ser ud:

    \begin{description}[Average case]
        \pause
        \item[Worst case] Hvert rekursivt kald laver et enkelt nyt sub-problem
            af størrelse $n - 1$ $\to$ $\Theta(n^2)$
        \pause
        \item[Best case] Hvert rekursivt kald laver 2 nye sub-problemer af
            størrelse $n/2 \to \Theta(n \log n)$
        \pause
        \item[Average case] Hvis det rekursive kald skifter mellem at producere
            `gode' og `dårlige' split, så vil de `dårlige' split blive
            absorberet af de `gode', og dybden af rekursionen vil fortsat være
            bundet af $O(\log n) \to \,$ dermed har det kun en effekt på den
            skjulte konstant med kompleksiteten fortsætter med at være $\Theta(n
            \log n)$
    \end{description}

    \pause
    Hvordan kan vi sikre os ikke at ramme worst-case? \pause
    \alert{Randomization!}
\end{frame}

\begin{frame}{Quicksort}{Randomized quicksort}
    \centering
    \begin{minipage}{.6\textwidth}
        \begin{block}{Randomized-Partition($A,p,r$)}

            \vspace{-\abovedisplayskip}
            \begin{codebox}
                \li $i \gets \proc{Random}(p, r)$
                \li exchange $A[i]$ and $A[r]$
                \li \Return $\proc{Partition}(A,p,r)$
            \end{codebox}
        \end{block}
    \end{minipage}
\end{frame}


\section{Exercises}

\begin{frame}{Exercises!}{Yay!}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{exercises}
    \end{figure}
    
\end{frame}

\section{The Master Theorem}

\begin{frame}{Analyse af rekursioner}{3 metoder}
    Vi har set et par eksempler på divide-and-conquer-algoritmer, og hvordan de
    bruger rekursion til at løse deres opgave. Rekursioner kan godt være tricky
    at analysere og forstå, hvorfor der findes en række metoder til at gå til
    dem mere eller mindre formelt:

    \pause
    \begin{description}[The recursion-tree method]
        \item[The substitution method] I denne starter vi med et kvalificeret
            gæt, og så bruger vi matematisk induktion til at vise, at vi har
            ret. Kan være den nemmeste metode, men kræver lidt erfaring.
        \pause
        \item[The recursion-tree method] Vi kan tegne det træ, der fremkommer af
            rekursionen og bruge det visuelle til at understøtte vores
            forståelse af, hvad der sker. Altid en god øvelse!
        \pause
        \item[The Master Method] For rekursioner, der kan skrives op på formen
            \[
                T(n) = aT(n/b) + f(n)
            \] er dette den letteste og sikreste måde at garantere
            kompleksiteten af algoritmen. Og det er den metode, vi kigger
            nærmere ind i nu! 
    \end{description}
\end{frame}

\begin{frame}{Master method}{Introduktion}
    The master method giver os et værktøj, der kan løse rekursioner af formen
    \[
        T(n) = aT(n/b) + f(n)
    \] hvilket ofte er den form, som divide-and-conquer giver.

    \begin{itemize}
        \item $a$ og $b$ er konstanter, og vi kræver, at $a \geq 1$, $b > 1$
        \item Vi kalder $f(n)$ \alert{the driving function}, og kræver blot at
            den er en asymptotisk positiv funktion (dvs.\ ikke-negativ for alle
            tilpas store værdier af $n$)
        \item Med det kan vi benytte \alert{master teoremet}!
    \end{itemize}
\end{frame}

\begin{frame}{Master theorem}{Oh boy!}
    \begin{theorem}[Master theorem]
        \small
        Let $a > 0$ and $b > 1$ be constants, and let $f(n)$ be a driving
        function that is defined and nonnegative on all sufficiently large
        reals. Define the recurrence $T(n)$ on $n \in \mathbb{N}$ by

        \[
            T(n) = aT(n/b) + f(n)
        \] 

        where $aT(n/b)$ actually means $a'T(\lfloor n/b \rfloor) + a''T(\lceil
        n/b \rceil)$ for some constants $a' \geq 0$ and $a'' \geq 0$ satisfying
        $a = a' + a''$. Then the asymptotic behavior of $T(n)$ can be
        characterized as follows:

        \begin{enumerate}
            \pause
            \item If there exists a constant $\epsilon > 0$ such that $f(n) =
                O(n^{\log_b a-\epsilon})$, then $T(n) = \Theta(n^{\log_b a})$
            \pause
            \item If there exists a constant $k \geq 0$ such that $f(n) =
                \Theta(n^{\log_b a} \lg^kn)$ then $T(n) =
                \Theta(n^{\log_ba}\lg^{k+1}n)$
            \pause
            \item If there exists a constant $\epsilon > 0$ such that $f(n) =
                \Omega(n^{\log_b a+e})$ and if $f(n)$ aditionally satisfies the
                \alert{regularity condition} $af(n/b) \leq cf(n)$ for some
                constant $c < 1$ and all sufficiently large $n$, then $T(n) =
                \Theta(f(n))$
        \end{enumerate}
    \end{theorem}
\end{frame}

\begin{frame}[t]{Master theorem}{Lets break it down}
    \begin{theorem}[Master theorem (simplified)]
        \small
        For a recurrence of the form $T(n) = aT(n/b) + f(n)$, the asymptotic
        behavior of $T(n)$ can be characterized as follows:

        \begin{enumerate}
            \uncover<2->{%
            \item If there exists a constant $\epsilon > 0$ such that $f(n) =
                O(n^{\log_b a-\epsilon})$, then $T(n) = \Theta(n^{\log_b a})$
            }
            \uncover<3->{%
            \item If there exists a constant $k \geq 0$ such that $f(n) =
                \Theta(n^{\log_b a} \lg^kn)$ then $T(n) =
                \Theta(n^{\log_ba}\lg^{k+1}n)$
            }
            \uncover<4->{%
            \item If there exists a constant $\epsilon > 0$ such that $f(n) =
                \Omega(n^{\log_b a+e})$ and if $f(n)$ aditionally satisfies the
                \alert{regularity condition} $af(n/b) \leq cf(n)$ for some
                constant $c < 1$ and all sufficiently large $n$, then $T(n) =
                \Theta(f(n))$
            }
        \end{enumerate}
    \end{theorem}

    $f(n)$ kaldes en \alert{driving function} og $n^{\log_b a}$ kaldes en
    \alert{watershed function}. Vi sammenligner disse på følgende måder:

    \begin{description}
        \item[Case 1]<only@2> $f(n)$ er \alert{asymptotisk mindre} (jf. $O$) end $n^{\log_b
            a}$ med en faktor af $n^{\epsilon}$ (eftersom $n^{\log_b a -
            \epsilon} = \frac{n^{\log_b a}}{n^{\epsilon}}$) --- i så fald er
            rekursionen $T(n) = \Theta(n^{\log_b a})$

        \item[Case 2]<only@3> $f(n)$ er \alert{asymptotisk ækvivalent} (jf. $\Theta)$
            med $n^{\log_b a} \lg^k n$ for $k \geq 0$ --- i så fald er
            rekursionen $T(n) = \Theta(n^{\log_b a} \lg^{k+1} n)$

            \begin{itemize}
                \item Generelt kan $k=0$ antages, hvormed udtrykket bliver noget
                    simplere!
            \end{itemize}

        \item[Case 3]<only@4> $f(n)$ er \alert{asymptotisk større} (jf.
            $\Omega$) end $n^{\log_b a}$ med en faktor $n^{\epsilon}$ (igen,
            $n^{\log_b a + \epsilon} = n^{\log_b a} * n^{\epsilon}$) og lidt
            ekstra holder --- i så fald er rekursionen $T(n) = \Theta(f(n))$

            \begin{itemize}
                \small
                \item \alert{Regularitetsbetingelsen} holder for det meste, og I
                    behøver ikke hænge jer i den
            \end{itemize}
    \end{description}
\end{frame}

\begin{frame}{Master theorem}{Hvordan bruges det?}
    Følg denne opskrift:

    \begin{enumerate}
        \item Identificer om rekursionen har formen $T(n) = aT(n/b) + f(n)$
        \item Gør udtrykket $n^{\log_b a}$ simplere ved at indsætte $a$ og $b$
        \item Undersøg hvilket af de 3 cases, der holder, altså
            \begin{itemize}
                \item $f(n) = O(n^{\log_b a - \epsilon}) = O(n^{\log_b
                    a}/n^{\epsilon})$, hvor $\epsilon > 0$
                \item $f(n) = \Theta(n^{\log_b a}\lg^k n)$, for $k >= 0$
                \item $f(n) = \Omega(n^{\log_b a + \epsilon}) = \Omega(n^{\log_b
                    a} * n^{\epsilon})$, hvor $\epsilon > 0$
            \end{itemize}
        \item Konklusionen kan stadig se lidt kompliceret ud, så reducer
            yderligere
    \end{enumerate}
\end{frame}

\begin{frame}{Master theorem}{Eksempel}
    Vi identificerede tidligere, at vi kunne skrive \proc{Merge-Sort}s køretid
    op som rekursionen $T(n) = 2T(n/2) + \Theta(n)$. 

    \begin{align*}
        a&=\uncover<2->{2} \quad b=\uncover<3->{2} \quad
        f(n)=\uncover<4->{\Theta(n)} \\
        n^{\log_b a}&=\uncover<5->{n^{\log_2 2} = n^{1} = n} \\
    \end{align*}

    \uncover<5->{Nu tjekker vi så, om vi kan få det til at passe på nogle af
    teoremets cases:}
    \begin{itemize}
        \item<6-> Er $f(n) = O(n^{1 - \epsilon})$ for nogen $\epsilon > 0$?
        \item<7-> Er $f(n) = \Theta(n^{1}\lg^k n)$ for nogen $k >= 0$?
            \begin{itemize}
                \item<8-> Ja! For $k = 0$ har vi $\Theta(n^{1}\lg^{0}n) =
                    \Theta(n) = f(n)$.
                \pause
                \item<9-> Dette er \alert{case 2} i teoremet, som fortæller os at
                    $T(n) = \Theta(n^{\log_b a}\lg^{k+1}n$, hvilket for $a=2$,
                    $b=2$ og $k=0$ giver at $T(n) = \Theta(n \lg n)$
            \end{itemize}
    \end{itemize}
\end{frame}


\begin{frame}{Master theorem}{Endnu et eksempel}
    Vi prøver endnu et eksempel

    \begin{itemize}
        \item<2-> Vi har $T(n) = 3T(n/4) + n \lg n$
        \item<3-> Dermed har vi $a = \uncover<4->{3}$, $b=\uncover<4->{4}$ og
            $f(n)=\uncover<5->{n \lg n}$
        \item<6-> Vi indsætter og forenkler: $n^{\log_b a} = n^{\log_4 3} =
            n^{0.792}$ (ish)
    \end{itemize}

    \only<7->{Og så tjekker vi cases:}
    \begin{enumerate}
        \item<7-> Er $f(n) = O(n^{0.792 - \epsilon})$ for nogen $\epsilon > 0$?
            \begin{itemize}
                \item<8-> Nej, for $n^{0.792} < n$, hvilket stadig må gælde,
                    hvis vi fratrækker en positiv konstant i eksponenten, og da
                    $f(n) = n \lg n \geq n$ kan $n^{0.792 - \epsilon}$ altså
                    ikke være et upper bound.
            \end{itemize}
        \item<9-> Er $f(n) = \Theta(n^{0.792}\lg^k n)$ for nogen $k >= 0$?
            \begin{itemize}
                \item<10-> Nej, for hvis $k <= 1$ vokser $n^{0.792}\lg^{k}n$ for
                    langsomt, og hvis $k > 1$ vokser det for hurtigt
            \end{itemize}
        \item<11-> Er $f(n) = \Omega(n^{0.792 + \epsilon})$ for nogen $\epsilon > 0$?
            \begin{itemize}
                \item<12-> Ja! $n^{x}$ er et lower bound for $n\lg n$, så længe $x$
                    er mindre end 1. Dvs., at denne case holder for alle
                    $\epsilon < 0.2$ (ish)
                \item<12-> \alert{Case 3} giver os at $T(n) = \Theta(f(n)) =
                    \Theta(n \lg n)$
            \end{itemize}
    \end{enumerate}
\end{frame}


\begin{frame}{Dagens temaer}{Opsummering}
    \begin{itemize}
        \item Introduktion til \alert{divide-and-conquer} paradigmet
            \begin{itemize}
                \item Del problemet op i mindre sub-problemer
                \item Løs sub-problemerne når de er trivielle
                \item Kombiner løsningerne til en samlet løsning
            \end{itemize}
        \item Merge sort og Quicksort
            \begin{itemize}
                \item Merge sort er garanteret at køre i $\Theta(n \log n)$
                \item Quicksort kører i worst case i $\Theta(n^2)$ men kan nemt
                    sikres en forventet køretid i $\Theta(n \log n)$
            \end{itemize}
        \item Rekursioner og master theorem
            \begin{itemize}
                \item En generisk metode til at identificere køretider for
                    rekursioner på formen $T(n) = aT(n/b) + f(n)$
            \end{itemize}
    \end{itemize}
\end{frame}


\begin{frame}{Tak for i dag!}{Flere exercises..}

    Den bedste måde ikke at snyde sig selv på er lave exercises!

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{exercises}
    \end{figure}
    
\end{frame}



\end{document}


